{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "mount_file_id": "1CevKUyAxK2Lcq1OEFUWZUsswM9F-qf6s",
      "authorship_tag": "ABX9TyPOlH8C1t9YE4D8q5Zz2HH8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lucifer-1947/jio-data/blob/main/assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 1: Data Loading and Preprocessing\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "OeoWif0ruxP7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WeBT06iFuthm"
      },
      "outputs": [],
      "source": [
        "#1. Loading the dataset from the given CSV file into a Pandas Data Frame.\n",
        "\n",
        "import pandas as pd #importing pandas package module as pd\n",
        "\n",
        "#using pandas methods to read csv files\n",
        "#dataset.csv file is in the root-directory\n",
        "dataFrame = pd.read_csv('https://drive.google.com/file/d/1MFj8jTbSKOLfmfkIFzKjvI0wz5cCHRd4/view?usp=sharing')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2. Performing basic data preprocessing steps\n",
        "\n",
        "#region handling missing values\n",
        "print(dataFrame.isnull().sum())\n",
        "\n",
        "#if no.of missing content is less , we can drop them .\n",
        "dataFrame.dropna()\n",
        "\n",
        "#But missing contetnt is large , we need to fill by choosing necessary way like average value of the column  , probability based etc...\n",
        "#dataFrame.fillna(0)\n",
        "\n",
        "#endregion\n",
        "\n",
        "#region handling duplicates\n",
        "print(\"\\nduplicated :\",dataFrame.duplicated().sum())\n",
        "\n",
        "#since we don't need duplicates in the dataframe we can drop any deplicates.\n",
        "dataFrame.drop_duplicates()\n",
        "\n",
        "#endregion\n"
      ],
      "metadata": {
        "id": "qDCsNmMb8Y00"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#3. Displaying the first few rows of the cleaned dataset.\n",
        "print(dataFrame)"
      ],
      "metadata": {
        "id": "gkgapf9EO59P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 2: Exploratory Data Analysis\n"
      ],
      "metadata": {
        "id": "yap35wI1Ppbu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Data Visualization using data-visulization library matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#creating 2x2 grid of subplots , which has 4 grids each grid used for each column representation\n",
        "#each plot represents the count of each data\n",
        "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
        "\n",
        "# Plot 1: jobs (Bar Chart)\n",
        "jobCount = dataFrame['job'].value_counts()\n",
        "axes[0, 0].bar(jobCount.index, jobCount.values)\n",
        "axes[0, 0].set_title('Job Roles')\n",
        "axes[0, 0].set_xlabel('Job Role')\n",
        "axes[0, 0].set_ylabel('Count')\n",
        "\n",
        "# Plot 2: education (Bar Chart)\n",
        "educationCount = dataFrame['education'].value_counts()\n",
        "axes[0, 1].bar(educationCount.index, educationCount.values)\n",
        "axes[0, 1].set_title('Education Levels')\n",
        "axes[0, 1].set_xlabel('Education Level')\n",
        "axes[0, 1].set_ylabel('Count')\n",
        "\n",
        "# Plot 3: Gender (Pie Chart)\n",
        "genderCount = dataFrame['gender'].value_counts()\n",
        "axes[1, 0].bar(genderCount.index, genderCount.values)\n",
        "axes[1, 0].set_title('Gender')\n",
        "axes[1, 0].set_xlabel('Gender')\n",
        "axes[1, 0].set_ylabel('Count')\n",
        "\n",
        "# Plot 4: English-Speaking Status (Pie Chart)\n",
        "englishCount = dataFrame['English speaker'].value_counts()\n",
        "axes[1, 1].bar(englishCount.index, englishCount.values)\n",
        "axes[1, 1].set_title('English Speaking Status')\n",
        "axes[1, 1].set_xlabel('English Speaker')\n",
        "axes[1, 1].set_ylabel('Count')\n",
        "\n",
        "# Adjust layout\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the plots\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "W9LoCQlBPxNk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating 2x2 grid of subplots , which has 4 grids each grid used for each column representation\n",
        "#each plot represents the count of each data\n",
        "fig, axs = plt.subplots(2, 2, figsize=(12, 8))\n",
        "\n",
        "\n",
        "# Calculating & plotting the percentages for job roles\n",
        "jobPercentages = jobCount * 100\n",
        "axs[0, 0].pie(jobPercentages, labels=jobPercentages.index, autopct='%1.1f%%')\n",
        "axs[0, 0].set_title('Job Roles')\n",
        "\n",
        "\n",
        "# Calculating & plotting the percentages for education levels\n",
        "educationPercentages = educationCount * 100\n",
        "axs[0, 1].pie(educationPercentages, labels=educationPercentages.index, autopct='%1.1f%%')\n",
        "axs[0, 1].set_title('Education Levels')\n",
        "\n",
        "# Calculating & plotting the percentages for genders\n",
        "genderPercentages = genderCount * 100\n",
        "axs[1, 0].pie(genderPercentages, labels=genderPercentages.index, autopct='%1.1f%%')\n",
        "axs[1, 0].set_title('Genders')\n",
        "\n",
        "\n",
        "# Calculating & plotting the percentages for English-speaking groups\n",
        "englishPercentages = englishCount * 100\n",
        "axs[1, 1].pie(englishPercentages, labels=englishPercentages.index, autopct='%1.1f%%')\n",
        "axs[1, 1].set_title('English-Speaking Groups')\n",
        "\n",
        "# Adjust layout\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the plots\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "H_shAxNKWlru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 3: Gender and English speaker Analysis"
      ],
      "metadata": {
        "id": "v8yI6a2Acm2P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#1. Calculate the average education level for each gender group (Male, Female, Others).\n",
        "\n",
        "# Grouping the data by 'Gender'\n",
        "genderGroups = dataFrame.groupby('gender')\n",
        "\n",
        "#calculating the average education level\n",
        "average_education = genderGroups['education'].value_counts().unstack()\n",
        "\n",
        "\n",
        "# Plot the results\n",
        "average_education.plot(kind='bar', stacked=True, figsize=(10, 6))\n",
        "plt.title('Average Education Level by Gender')\n",
        "plt.xlabel('Gender')\n",
        "plt.ylabel('Percentage')\n",
        "plt.legend(title='Education Level')\n",
        "plt.show()\n",
        "\n",
        "#Results\n",
        "average_education['Total'] = average_education.sum(axis=1)\n",
        "average_education = average_education.div(average_education['Total'], axis=0).drop(columns='Total')\n",
        "print(average_education)\n"
      ],
      "metadata": {
        "id": "Eg5Auk58ctaA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#2. Comparing the distribution of job roles among different gender groups using a stacked bar chart.\n",
        "\n",
        "gender_job_groups = dataFrame.groupby(['gender', 'job']).size().unstack(fill_value=0)\n",
        "\n",
        "# Plot the stacked bar chart\n",
        "gender_job_groups.plot(kind='bar', stacked=True, figsize=(10, 6))\n",
        "plt.title('Distribution of Job Roles Among Different Genders')\n",
        "plt.xlabel('Gender')\n",
        "plt.ylabel('Count')\n",
        "plt.legend(title='Job Role')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vTfz-ngjrnOU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#3. Create a histogram to show the distribution of education levels among English speaking and non-English speaking individuals.\n",
        "\n",
        "\n",
        "#Spliting the data into two groups: English-speaking and non-English speaking\n",
        "english_speaking = dataFrame[dataFrame['English speaker'] == 'yes']\n",
        "non_english_speaking = dataFrame[dataFrame['English speaker'] == 'no']\n",
        "\n",
        "# Create histograms for education levels in each group\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "plt.hist(english_speaking['education'], bins=3, alpha=0.5, label='English Speaking')\n",
        "plt.hist(non_english_speaking['education'], bins=3, alpha=0.5, label='Non-English Speaking')\n",
        "\n",
        "plt.title('Distribution of Education Levels Among English Speaking and Non-English Speaking Individuals')\n",
        "plt.xlabel('Education Level')\n",
        "plt.ylabel('Count')\n",
        "plt.legend()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BjtPQ7ums93H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 4: Predictive Modeling"
      ],
      "metadata": {
        "id": "_u1tR51L8rqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#1. Encode categorical variables (job, education, gender, English speaker) using appropriate techniques (e.g., one-hot encoding).\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Using One-Hot-Encoding for categorical Variables\n",
        "df_encoded = pd.get_dummies(dataFrame, columns=['job', 'education', 'English speaker'])\n",
        "\n",
        "print(df_encoded)"
      ],
      "metadata": {
        "id": "lEC1rjSw82Rm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Split the dataset into training and testing sets (80% training, 20% testing)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Definig our targeted column which is gender\n",
        "X = df_encoded[['job_admin', 'job_custodial', 'job_manage', 'education_8', 'education_12','education_14','education_15','education_16','education_17','education_18','education_19','education_20','education_21','English speaker_no','English speaker_yes']]\n",
        "y = dataFrame['gender']\n",
        "\n",
        "# Splitting the data into training(80%) test(20%)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "9SbIF2MfLRMx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#3. Build a classification model to predict the gender of individuals based on job role,education level, and English-speaking status.\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Random Forest Classification Model\n",
        "clf = RandomForestClassifier(random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Making predictions on the test data of 80%\n",
        "y_pred = clf.predict(X_test)\n",
        "\n"
      ],
      "metadata": {
        "id": "6ie2jJxeRN0H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#4. Evaluate the model's performance using accuracy, precision, recall, and F1-score metrics.\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc\n",
        "\n",
        "# Evaluating the model's performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1-score: {f1:.2f}\")"
      ],
      "metadata": {
        "id": "Fp5PjTisR7bF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#5. Use feature importance techniques (e.g., feature importance scores, permutation feature importance) to identify the most influential features for gender prediction.\n",
        "\n",
        "from sklearn.inspection import permutation_importance\n",
        "\n",
        "# Calculating feature importance using permutation importance\n",
        "perm_importance = permutation_importance(clf, X_test, y_test, n_repeats=30, random_state=42)\n",
        "\n",
        "# Getting the feature names and their importances\n",
        "feature_names = X_test.columns\n",
        "importances = perm_importance.importances_mean\n",
        "\n",
        "# Creating a DataFrame to store feature names and their importances\n",
        "importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
        "\n",
        "# Sorting the DataFrame by importance in descending order\n",
        "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Print the top influential features\n",
        "print(\"Top Influential Features:\")\n",
        "print(importance_df)"
      ],
      "metadata": {
        "id": "uUjxYN0QSJ4c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#6. Visualizing the ROC curve and AUC score for the gender prediction model.\n",
        "\n",
        "# Calculate ROC curve\n",
        "y_probs = clf.predict_proba(X_test)[:, 1]\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_probs,pos_label=1)\n",
        "\n",
        "# Calculate AUC (Area Under the ROC Curve)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# Visualize ROC curve\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "lajUvwnZScAN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}